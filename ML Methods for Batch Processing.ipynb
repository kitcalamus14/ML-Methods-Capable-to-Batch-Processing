{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After some research, I found that the term used in sklearn for batch processing large dataset are known as partial_fit features, which was explained as 'out-of-core' or external-memory training. Whichever method that support this features will allow the model to be trained batch by batch. \n",
    "#### reference (https://scikit-learn.org/0.15/modules/scaling_strategies.html)\n",
    "\n",
    "#### As stated in the link, these ML methods were designed to support partial_fit\n",
    "#### Classification\n",
    "#### 1. sklearn.naive_bayes.MultinomialNB\n",
    "#### 2. sklearn.naive_bayes.BernoulliNB\n",
    "#### 3. sklearn.linear_model.Perceptron\n",
    "#### 4. sklearn.linear_model.SGDClassifier\n",
    "#### 5. sklearn.linear_model.PassiveAggressiveClassifier\n",
    "\n",
    "#### Regression\n",
    "#### 1. sklearn.linear_model.SGDRegressor\n",
    "#### 2. sklearn.linear_model.PassiveAggressiveRegressor\n",
    "\n",
    "#### Clustering\n",
    "#### 1. sklearn.cluster.MiniBatchKMeans\n",
    "\n",
    "#### Decomposition / feature Extraction\n",
    "#### 1. sklearn.decomposition.MiniBatchDictionaryLearning\n",
    "#### 2. sklearn.cluster.MiniBatchKMeans\n",
    "\n",
    "#### The following coding will experiment the MultinomialNB using Iris dataset, performance was evaluated through the comparison of default Multinomial with fit and Multinomial model train through partial_fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import choice, randint\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4551"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('iris.txt','wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        names\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['sepal_length','sepal_width','petal_length','petal_width','names']\n",
    "df = pd.read_csv('iris.txt',names = header,index_col =False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def name_to_numeric(x):\n",
    "    if x=='Iris-setosa':return 0\n",
    "    if x =='Iris-versicolor':return 1\n",
    "    if x =='Iris-virginica':return 2\n",
    "\n",
    "df['names'] = df['names'].apply(name_to_numeric)\n",
    "df.to_csv('new iris.csv', header=False,index=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly selecting small amount of dataset from new iris.csv\n",
    "selected_list = []\n",
    "choice([i for i in range(0,151) if i not in []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data_selector():\n",
    "    \n",
    "    exclude = []\n",
    "    final_lst = []\n",
    "    for X in range(6):\n",
    "        selection =[]\n",
    "        while len(selection)< 20:\n",
    "            randInt = randint(0,149)\n",
    "            if randInt in exclude:\n",
    "                continue\n",
    "            else:\n",
    "                exclude.append(randInt)\n",
    "                selection.append(randInt)\n",
    "        final_lst.append(selection)\n",
    "    return final_lst,exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand,exclude = random_data_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min for this list is  4\n",
      "max for this list is  131 \n",
      "\n",
      "min for this list is  2\n",
      "max for this list is  149 \n",
      "\n",
      "min for this list is  0\n",
      "max for this list is  145 \n",
      "\n",
      "min for this list is  7\n",
      "max for this list is  143 \n",
      "\n",
      "min for this list is  1\n",
      "max for this list is  142 \n",
      "\n",
      "min for this list is  13\n",
      "max for this list is  148 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fail-safe checking, min must be =0 max must be 149\n",
    "for list in rand:\n",
    "    print('min for this list is ', min(list))\n",
    "    print('max for this list is ', max(list), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120\n"
     ]
    }
   ],
   "source": [
    "#check if number duplicated, set function only return unique value in a list)\n",
    "flat_list = [item for sublist in rand for item in sublist]\n",
    "print(len(flat_list),len(set(flat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the remaining 30 entries of data for testing set\n",
    "test_indexes = [i for i in range(0,150) if i not in exclude]\n",
    "df_test = pd.DataFrame(columns = ['sepal_length','sepal_width','petal_length','petal_width','names'])\n",
    "for index in test_indexes:\n",
    "    line = pd.read_csv('new iris.csv',skiprows = index-1,nrows=1,header=None,names = ['sepal_length','sepal_width','petal_length','petal_width','names'])\n",
    "    df_test = pd.concat([df_test,line])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Constructing ML model\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch 0  done\n",
      "minibatch 1  done\n",
      "minibatch 2  done\n",
      "minibatch 3  done\n",
      "minibatch 4  done\n",
      "minibatch 5  done\n",
      "Wall time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in range(6):\n",
    "    indexes = rand[x]\n",
    "    minidf = pd.DataFrame(columns = ['sepal_length','sepal_width','petal_length','petal_width','names'])\n",
    "    for index in indexes:\n",
    "        line = pd.read_csv('new iris.csv',skiprows= index-1,nrows=1,header=None,names = ['sepal_length','sepal_width','petal_length','petal_width','names'])\n",
    "        minidf = pd.concat([minidf,line])\n",
    "    X = minidf.iloc[:,:4]\n",
    "    y = minidf.iloc[:,-1]\n",
    "    y = y.astype('int')\n",
    "\n",
    "    if x == 0: nb.fit(X,y)\n",
    "    if x == 1:nb.partial_fit(X,y,classes=np.unique(y))\n",
    "    else: nb.partial_fit(X,y)\n",
    "    \n",
    "\n",
    "    print('minibatch {}  done'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_test = df_test.iloc[:,:4]\n",
    "y_test = df_test.iloc[:,-1]\n",
    "y_pred = nb.predict(X_test)\n",
    "y_test = np.array(y_test.values).astype('int')\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The result can be further improve by disabling the fit_prior feature. The improvement is due to each minibatch could be providing different number of class ratio (setosa, verginica, and versicolor), and assuming the probability based on the earlier batches is misleading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch 0  done\n",
      "minibatch 1  done\n",
      "minibatch 2  done\n",
      "minibatch 3  done\n",
      "minibatch 4  done\n",
      "minibatch 5  done\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(fit_prior = False)\n",
    "for x in range(6):\n",
    "    indexes = rand[x]\n",
    "    minidf = pd.DataFrame(columns = ['sepal_length','sepal_width','petal_length','petal_width','names'])\n",
    "    for index in indexes:\n",
    "        line = pd.read_csv('new iris.csv',skiprows= index-1,nrows=1,header=None,names = ['sepal_length','sepal_width','petal_length','petal_width','names'])\n",
    "        minidf = pd.concat([minidf,line])\n",
    "    X = minidf.iloc[:,:4]\n",
    "    y = minidf.iloc[:,-1]\n",
    "    y = y.astype('int')\n",
    "\n",
    "    if x == 0: nb.fit(X,y)\n",
    "    if x == 1:nb.partial_fit(X,y,classes=np.unique(y))\n",
    "    else: nb.partial_fit(X,y)\n",
    "\n",
    "    print('minibatch {}  done'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test.iloc[:,:4]\n",
    "y_test = df_test.iloc[:,-1]\n",
    "y_pred = nb.predict(X_test)\n",
    "y_test = np.array(y_test.values).astype('int')\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_numeric(x):\n",
    "    if x=='Iris-setosa':return 0\n",
    "    if x =='Iris-versicolor':return 1\n",
    "    if x =='Iris-virginica':return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "####Standard fit all data method\n",
    "header = ['sepal_length','sepal_width','petal_length','petal_width','names']\n",
    "df = pd.read_csv('iris.txt',names = header,index_col =False)\n",
    "df.head(10)\n",
    "df['names'] = df['names'].apply(name_to_numeric)\n",
    "X = df.iloc[:,:-1]\n",
    "y = (df.iloc[:,-1:])\n",
    "X_train, X_test, y_train, y_test = train_test_split( X,y, test_size = 0.2, random_state = 500)\n",
    "dtc = MultinomialNB(fit_prior=False)\n",
    "dtc.fit(X_train, np.ravel(y_train))\n",
    "y_pred = dtc.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusively, the standard fit all method performs well with slightly low accuracy compare to the partial fit version which is assumed can be improved by hyperparameter tuning, However, runtime-wise, partial_fit induces significant more runtime. Nevertheless, runtime and accuracy shouldn't be a concern when it comes to choosing between fit or partial fit. Rather, partial fit should only be used when there is hardware limitations.\n",
    "\n",
    "#### In this project, the partial fit feature was experimented and could be recycle use on other support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
